{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1a064b",
   "metadata": {},
   "source": [
    "Reference: \n",
    "- https://github.com/NVIDIA/DeepRecommender/blob/master/reco_encoder/model/model.py\n",
    "- https://github.com/L1aoXingyu/pytorch-beginner/blob/master/08-AutoEncoder/simple_autoencoder.py\n",
    "- https://users.cecs.anu.edu.au/~akmenon/papers/autorec/autorec-paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b128ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9acdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe7f39",
   "metadata": {},
   "source": [
    "### 1. Implement model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d36e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSEloss(inputs, targets):\n",
    "    mask = targets != 0\n",
    "    num_ratings = torch.sum(mask.float())\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    return criterion(inputs * mask.float(), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e246a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(size, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(True), \n",
    "            nn.Linear(64, size), \n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4bd55",
   "metadata": {},
   "source": [
    "### 2. Load and process data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419cb255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"datasets/movie_ratings.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a65c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieId                                                    ...                  \n",
       "1          4  0.0  0.0    0    4    0  4.5    0    0  0.0  ...  4.0    0    4   \n",
       "2          0  0.0  0.0    0    0    4  0.0    4    0  0.0  ...  0.0    4    0   \n",
       "3          4  0.0  0.0    0    0    5  0.0    0    0  0.0  ...  0.0    0    0   \n",
       "4          0  0.0  0.0    0    0    3  0.0    0    0  0.0  ...  0.0    0    0   \n",
       "5          0  0.0  0.0    0    0    5  0.0    0    0  0.0  ...  0.0    0    0   \n",
       "\n",
       "userId   604  605  606  607  608  609  610  \n",
       "movieId                                     \n",
       "1          3  4.0  2.5    4  2.5    3  5.0  \n",
       "2          5  3.5  0.0    0  2.0    0  0.0  \n",
       "3          0  0.0  0.0    0  2.0    0  0.0  \n",
       "4          0  0.0  0.0    0  0.0    0  0.0  \n",
       "5          3  0.0  0.0    0  0.0    0  0.0  \n",
       "\n",
       "[5 rows x 610 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.pivot_table(raw, values=\"rating\", index=\"movieId\", columns=\"userId\", fill_value=0.0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55ca0b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938aaef1",
   "metadata": {},
   "source": [
    "### 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d3ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "weight_decay=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70787ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_small = DataLoader(tensor[:10, :], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bda0963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(tensor, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b2fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(size=tensor.shape[1])\n",
    "criterion = MSEloss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac0ac26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss:1892.91\n",
      "epoch [2/200], loss:1927.505\n",
      "epoch [3/200], loss:1884.451\n",
      "epoch [4/200], loss:1709.866\n",
      "epoch [5/200], loss:1560.298\n",
      "epoch [6/200], loss:1421.942\n",
      "epoch [7/200], loss:1292.482\n",
      "epoch [8/200], loss:1199.969\n",
      "epoch [9/200], loss:1130.861\n",
      "epoch [10/200], loss:1052.132\n",
      "epoch [11/200], loss:964.171\n",
      "epoch [12/200], loss:878.151\n",
      "epoch [13/200], loss:846.915\n",
      "epoch [14/200], loss:775.89\n",
      "epoch [15/200], loss:756.796\n",
      "epoch [16/200], loss:737.935\n",
      "epoch [17/200], loss:728.605\n",
      "epoch [18/200], loss:683.943\n",
      "epoch [19/200], loss:644.844\n",
      "epoch [20/200], loss:643.204\n",
      "epoch [21/200], loss:622.143\n",
      "epoch [22/200], loss:613.358\n",
      "epoch [23/200], loss:590.139\n",
      "epoch [24/200], loss:575.745\n",
      "epoch [25/200], loss:567.418\n",
      "epoch [26/200], loss:581.667\n",
      "epoch [27/200], loss:571.942\n",
      "epoch [28/200], loss:561.083\n",
      "epoch [29/200], loss:569.798\n",
      "epoch [30/200], loss:532.377\n",
      "epoch [31/200], loss:527.207\n",
      "epoch [32/200], loss:512.491\n",
      "epoch [33/200], loss:503.765\n",
      "epoch [34/200], loss:491.548\n",
      "epoch [35/200], loss:485.598\n",
      "epoch [36/200], loss:481.616\n",
      "epoch [37/200], loss:470.669\n",
      "epoch [38/200], loss:463.262\n",
      "epoch [39/200], loss:467.066\n",
      "epoch [40/200], loss:454.401\n",
      "epoch [41/200], loss:458.458\n",
      "epoch [42/200], loss:433.013\n",
      "epoch [43/200], loss:422.572\n",
      "epoch [44/200], loss:421.849\n",
      "epoch [45/200], loss:401.679\n",
      "epoch [46/200], loss:387.829\n",
      "epoch [47/200], loss:373.148\n",
      "epoch [48/200], loss:365.879\n",
      "epoch [49/200], loss:351.172\n",
      "epoch [50/200], loss:351.598\n",
      "epoch [51/200], loss:344.019\n",
      "epoch [52/200], loss:346.29\n",
      "epoch [53/200], loss:348.619\n",
      "epoch [54/200], loss:334.844\n",
      "epoch [55/200], loss:329.316\n",
      "epoch [56/200], loss:319.335\n",
      "epoch [57/200], loss:316.144\n",
      "epoch [58/200], loss:306.179\n",
      "epoch [59/200], loss:299.461\n",
      "epoch [60/200], loss:300.414\n",
      "epoch [61/200], loss:291.37\n",
      "epoch [62/200], loss:286.362\n",
      "epoch [63/200], loss:284.909\n",
      "epoch [64/200], loss:285.586\n",
      "epoch [65/200], loss:288.895\n",
      "epoch [66/200], loss:294.628\n",
      "epoch [67/200], loss:294.607\n",
      "epoch [68/200], loss:284.739\n",
      "epoch [69/200], loss:260.905\n",
      "epoch [70/200], loss:268.418\n",
      "epoch [71/200], loss:267.49\n",
      "epoch [72/200], loss:254.611\n",
      "epoch [73/200], loss:246.151\n",
      "epoch [74/200], loss:243.562\n",
      "epoch [75/200], loss:249.804\n",
      "epoch [76/200], loss:242.462\n",
      "epoch [77/200], loss:243.641\n",
      "epoch [78/200], loss:243.852\n",
      "epoch [79/200], loss:248.099\n",
      "epoch [80/200], loss:244.445\n",
      "epoch [81/200], loss:242.306\n",
      "epoch [82/200], loss:241.919\n",
      "epoch [83/200], loss:244.849\n",
      "epoch [84/200], loss:247.144\n",
      "epoch [85/200], loss:229.145\n",
      "epoch [86/200], loss:220.506\n",
      "epoch [87/200], loss:219.991\n",
      "epoch [88/200], loss:227.529\n",
      "epoch [89/200], loss:217.587\n",
      "epoch [90/200], loss:215.449\n",
      "epoch [91/200], loss:213.403\n",
      "epoch [92/200], loss:207.245\n",
      "epoch [93/200], loss:203.213\n",
      "epoch [94/200], loss:202.828\n",
      "epoch [95/200], loss:220.053\n",
      "epoch [96/200], loss:214.891\n",
      "epoch [97/200], loss:228.062\n",
      "epoch [98/200], loss:226.901\n",
      "epoch [99/200], loss:221.308\n",
      "epoch [100/200], loss:224.546\n",
      "epoch [101/200], loss:219.052\n",
      "epoch [102/200], loss:218.623\n",
      "epoch [103/200], loss:210.905\n",
      "epoch [104/200], loss:213.274\n",
      "epoch [105/200], loss:205.323\n",
      "epoch [106/200], loss:188.639\n",
      "epoch [107/200], loss:196.093\n",
      "epoch [108/200], loss:216.645\n",
      "epoch [109/200], loss:219.072\n",
      "epoch [110/200], loss:228.819\n",
      "epoch [111/200], loss:228.191\n",
      "epoch [112/200], loss:230.057\n",
      "epoch [113/200], loss:215.053\n",
      "epoch [114/200], loss:204.348\n",
      "epoch [115/200], loss:195.308\n",
      "epoch [116/200], loss:184.006\n",
      "epoch [117/200], loss:187.733\n",
      "epoch [118/200], loss:177.306\n",
      "epoch [119/200], loss:178.607\n",
      "epoch [120/200], loss:197.538\n",
      "epoch [121/200], loss:211.21\n",
      "epoch [122/200], loss:194.206\n",
      "epoch [123/200], loss:187.986\n",
      "epoch [124/200], loss:184.283\n",
      "epoch [125/200], loss:174.127\n",
      "epoch [126/200], loss:173.207\n",
      "epoch [127/200], loss:162.798\n",
      "epoch [128/200], loss:157.915\n",
      "epoch [129/200], loss:181.37\n",
      "epoch [130/200], loss:177.727\n",
      "epoch [131/200], loss:170.567\n",
      "epoch [132/200], loss:159.535\n",
      "epoch [133/200], loss:172.473\n",
      "epoch [134/200], loss:163.926\n",
      "epoch [135/200], loss:176.184\n",
      "epoch [136/200], loss:167.923\n",
      "epoch [137/200], loss:160.93\n",
      "epoch [138/200], loss:154.142\n",
      "epoch [139/200], loss:163.631\n",
      "epoch [140/200], loss:150.024\n",
      "epoch [141/200], loss:158.714\n",
      "epoch [142/200], loss:163.005\n",
      "epoch [143/200], loss:137.086\n",
      "epoch [144/200], loss:148.681\n",
      "epoch [145/200], loss:163.413\n",
      "epoch [146/200], loss:164.28\n",
      "epoch [147/200], loss:164.187\n",
      "epoch [148/200], loss:176.263\n",
      "epoch [149/200], loss:218.259\n",
      "epoch [150/200], loss:157.324\n",
      "epoch [151/200], loss:149.042\n",
      "epoch [152/200], loss:151.717\n",
      "epoch [153/200], loss:181.467\n",
      "epoch [154/200], loss:230.803\n",
      "epoch [155/200], loss:187.885\n",
      "epoch [156/200], loss:172.421\n",
      "epoch [157/200], loss:173.606\n",
      "epoch [158/200], loss:157.252\n",
      "epoch [159/200], loss:154.525\n",
      "epoch [160/200], loss:159.178\n",
      "epoch [161/200], loss:155.831\n",
      "epoch [162/200], loss:154.215\n",
      "epoch [163/200], loss:153.982\n",
      "epoch [164/200], loss:151.063\n",
      "epoch [165/200], loss:147.298\n",
      "epoch [166/200], loss:140.05\n",
      "epoch [167/200], loss:140.509\n",
      "epoch [168/200], loss:152.482\n",
      "epoch [169/200], loss:134.721\n",
      "epoch [170/200], loss:156.449\n",
      "epoch [171/200], loss:155.85\n",
      "epoch [172/200], loss:152.16\n",
      "epoch [173/200], loss:138.822\n",
      "epoch [174/200], loss:151.778\n",
      "epoch [175/200], loss:147.589\n",
      "epoch [176/200], loss:137.635\n",
      "epoch [177/200], loss:138.871\n",
      "epoch [178/200], loss:142.56\n",
      "epoch [179/200], loss:132.699\n",
      "epoch [180/200], loss:147.248\n",
      "epoch [181/200], loss:147.759\n",
      "epoch [182/200], loss:152.038\n",
      "epoch [183/200], loss:157.364\n",
      "epoch [184/200], loss:141.669\n",
      "epoch [185/200], loss:138.578\n",
      "epoch [186/200], loss:144.697\n",
      "epoch [187/200], loss:137.951\n",
      "epoch [188/200], loss:144.828\n",
      "epoch [189/200], loss:133.639\n",
      "epoch [190/200], loss:144.916\n",
      "epoch [191/200], loss:151.874\n",
      "epoch [192/200], loss:142.804\n",
      "epoch [193/200], loss:143.175\n",
      "epoch [194/200], loss:135.906\n",
      "epoch [195/200], loss:136.466\n",
      "epoch [196/200], loss:136.594\n",
      "epoch [197/200], loss:146.987\n",
      "epoch [198/200], loss:142.54\n",
      "epoch [199/200], loss:135.472\n",
      "epoch [200/200], loss:131.555\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for inputs in data:\n",
    "        # forward\n",
    "        targets = model(inputs.float())\n",
    "        loss = criterion(inputs.float(), targets.float())\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # log\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], loss:{round(float(loss), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060ce3f",
   "metadata": {},
   "source": [
    "### 4. Analysis\n",
    "The output is the rating prediction, and we need to remove the movied user already watched when generating a recommend list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40e0d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is 4.0 and output is 1.8!\n",
      "Input is 0.0 and output is 0.0!\n",
      "Input is 0.0 and output is 0.0!\n",
      "Input is 0.0 and output is 0.0!\n",
      "Input is 4.0 and output is 2.8!\n",
      "Input is 0.0 and output is 0.0!\n",
      "Input is 4.5 and output is 2.8!\n",
      "Input is 0.0 and output is 0.0!\n"
     ]
    }
   ],
   "source": [
    "# Test the first row and its first 8 elements.\n",
    "for x, y in zip(tensor[0, :8], model(tensor[0, :].float())[:8]):\n",
    "    print(f\"Input is {x} and output is {round(float(y), 1)}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cbeb333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(84, 3.731),\n",
       " (122, 3.102),\n",
       " (415, 2.874),\n",
       " (426, 2.603),\n",
       " (58, 2.488),\n",
       " (198, 2.325),\n",
       " (377, 2.285),\n",
       " (376, 2.26),\n",
       " (387, 2.047),\n",
       " (37, 1.996)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List top 10 recommend list of movie 1\n",
    "result = []\n",
    "for x, y, i in zip(tensor[0, :], model(tensor[0, :].float()), range(1, tensor.shape[1] + 1)):\n",
    "    if x > 0.0001:\n",
    "        continue\n",
    "    result.append((i, round(float(y), 3)))\n",
    "    \n",
    "sorted(result, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940cbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recommend list length plus the viewed list length equals to total number of movies. \n",
    "assert len(result) + sum(float(x) != 0 for x in tensor[0, :]) == tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bf3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
